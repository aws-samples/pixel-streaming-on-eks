# Deployment steps for the demo

## Prerequisites
Please ensure your environment meets the following requirements necessary for deployment.

- You have built an Unreal Engine Pixel Streaming application using the instructions [here](./UNREAL_ENGINE_EN.md)
- The required AWS IAM permissions (IAM roles, IAM users, etc.) are set.
    - Administrator-level privileges are necessary.
- You're logged in to Docker with a GitHub account linked to your Unreal Engine account. << TODO Do we need this if we use own game binary?
    - For authentication methods, please refer to  [Working with the Container registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#container-registry%E3%81%A7%E3%81%AE%E8%AA%8D%E8%A8%BC).
    TODO personal access token classic, scope: read/write/delete:packages
- The necessary software is installed.
    - Node.js (LTS version)
    - Docker
        - If you are using an ARM64 development environment, for example an M1 Mac, please set up to build images as AMD64.
    - Packer
    - kubectl
    - helm
    - [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
    - [AWS Cloud Development Kit (AWS CDK)](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html#getting_started_install)


## Building the AMI

Build an AMI with the latest NVIDIA GPU drivers for the EKS cluster worker node.

1. Install the required Packer plugins and navigate to the [Packer template directory](../packer/).

```console
$ packer plugins install github.com/hashicorp/amazon
$ cd pixel-streaming-on-eks/packer
```

2. Create the instance profile needed for the Packer AMI builder instance to download the NVIDIA drivers

```console
$ aws iam create-role --role-name packer-instance-role --assume-role-policy-document file://packer-instance-trust-policy.json
$ aws iam create-policy --policy-name packer-instance-profile-policy --policy-document file://packer-instance-profile-policy.json
$ PACKER_ACCOUNT_ID=`aws sts get-caller-identity --query "Account" --output text`
$ aws iam attach-role-policy --role-name packer-instance-role --policy-arn "arn:aws:iam::$PACKER_ACCOUNT_ID:policy/packer-instance-profile-policy"
$ aws iam create-instance-profile --instance-profile-name packer-instance-profile
$ aws iam add-role-to-instance-profile --instance-profile-name packer-instance-profile --role-name packer-instance-role
```

3. Update the region and Kubernetes variables in the command below and execute the command to build the AMI for the pixel streaming node.

```console
$ packer build -var 'region=eu-west-2' -var 'k8_version=1.30' eks-gpu-node.pkr.hcl
```

4. Once the build completes successfully, take note of the AMI ID that begins with `ami-`. 

```console
==> amazon-ebs: Creating AMI eks-gpu-node-1.24-1676732590 from instance i-012346789012df
    amazon-ebs: AMI: ami-0123456789012
==> amazon-ebs: Waiting for AMI to become ready...
```

You can also query for the AMI ID using the AWS CLI.

```console
$ aws ec2 describe-images --owners self --filters "Name=tag:Name,Values=Packer*" --query 'Images[*].[ImageId,Name,ImageType,CreationDate]' --output table
```

5. Then make sure to remove the instance profile, role, and policy that are no longer needed.

```console
$ aws iam detach-role-policy --role-name packer-instance-role --policy-arn "arn:aws:iam::$PACKER_ACCOUNT_ID:policy/packer-instance-profile-policy"
$ aws iam remove-role-from-instance-profile --instance-profile-name packer-instance-profile --role-name packer-instance-role
$ aws iam delete-role --role-name packer-instance-role
$ aws iam delete-policy --policy-arn "arn:aws:iam::$PACKER_ACCOUNT_ID:policy/packer-instance-profile-policy"
```

## Deploying the CDK App
1. We will no deploy the CDK App, which includes the EKS Cluster and Docker container images.

If you are currently in the `packer` directory, return to the directory above. Ensure that there is a `cdk.json` file in the same directory.

```console
$ ls
README.md  cdk.json ...
```

2. Open the [lib/eks-cluster-stack.ts](../lib/eks-cluster-stack.ts) TypeScripts CDK file and update the deployment specific variables.

    a) `EKS_ACCESS_ROLE` 

    Change this to the name of an existing role or user to the EKS cluster. By default, a role named Admin is the target. If you prefer to set this outside of the CDK deployment, refer to [Enabling IAM principal access to your cluster](https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html)  for guidance.

    b) `SOURCE_CIDR`

    Update this to the IP range of the device(s) that you will access the pixel streaming demo from. Best practice is to set this to a small range and not provide access to all external IPs.

    c) `AMI_ID`

    Update this constant to the ID of the AMI that was generated by the Packer build process.

3. Install all Node dependencies and [bootstrap the CDK environment](https://docs.aws.amazon.com/cdk/v2/guide/bootstrapping.html), if required.

```console
$ npm install
$ npx cdk bootstrap 
```

5. Execute the following commands to deploy. Please run `npm install` and `npx cdk bootstrap` only for the first time.

```console
$ npx cdk deploy --all --require-approval never

Outputs:
UnrealPixelStreamingStack.EksClusterConfigCommand2AE6ED67 = aws eks update-kubeconfig --name EksClusterFAB68BDB-25b7897febe6406db6795748575ae956 --region ap-northeast-1 --role-arn arn:aws:iam::...
UnrealPixelStreamingStack.EksClusterGetTokenCommandDF0BEDB9 = aws eks get-token --cluster-name EksClusterFAB68BDB-25b7897febe6406db6795748575ae956 --region ap-northeast-1 --role-arn arn:aws:iam::...
```

6. The line beginning with `UnrealPixelStreamingStack.EksClusterConfigCommand` that is output to the log is the command to configure kubectl. Copy and paste it to execute.
TODO This output wasn't created ...
```
$ aws eks update-kubeconfig --name PrototypeEksCluster --region <REGION>
```

## Setting Up EKS to Handle GPU
We will deploy the k8s-device-plugin and set up CUDA Time-Slicing.

1. Install nvidia-device-plugin using helm.
```
$ helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
$ helm repo update
$ helm upgrade -i nvdp nvdp/nvidia-device-plugin \
    --namespace nvidia-device-plugin \
    --create-namespace \
    --version 0.15.0 \
    --set-file config.map.config=./manifests/nvidia-device-plugin-config.yaml
```

2. Wait for a while, then run `kubectl describe node`. If you can see four GPUs, then it's working correctly.
```
$ kubectl describe node | grep nvidia.com/gpu:
  nvidia.com/gpu:              1
  nvidia.com/gpu:              1
↑ State with one GPU

$ kubectl describe node | grep nvidia.com/gpu:
  nvidia.com/gpu:              4
  nvidia.com/gpu:              4
↑ State with four GPUs
```

## Deploying the Demo App
1. Execute `./scripts/deploy_demo.sh N`. `N` specifies the number of deployments. (Example: `./scripts/deploy_demo.sh 1`)
   Wait for a while, then execute ./scripts/get_addresses.sh to retrieve the URL for access.
```
$ ./scripts/get_addresses.sh
http://18.183.134.12:30000
```

## Deleting the Deployed Environment
You can delete the deployed environment with the following command. Since some components cannot be removed from CDK and will remain, open the CloudFormation Console to check and manually delete them if unnecessary.
```
$ npx cdk destroy --all
```
